{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "cf5d3475-167e-4581-a5f0-aa3f17ef65c1",
   "metadata": {},
   "source": [
    "Dataset is sourced from Kaggle https://www.kaggle.com/datasets/arashnic/book-recommendation-dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09d1137f-c502-404d-8fe5-25415a015071",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "conda install -c conda-forge scikit-surprise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e392e04-3a8f-4d8a-87a9-9da48142f596",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# allows us to access dataframes\n",
    "import pandas as pd\n",
    "import scipy as sp\n",
    "import operator\n",
    "\n",
    "# specialized class for handling sparse matrices (compressed)\n",
    "from scipy.sparse import csr_matrix, csc_matrix\n",
    "\n",
    "# Library for visualizing charts\n",
    "import matplotlib.pylab as plt\n",
    "\n",
    "\n",
    "# Gives us access to the unsupervised algorithm knn \n",
    "from sklearn.neighbors import NearestNeighbors\n",
    "\n",
    "# Surprise is an easy-to-use Python scikit for recommender systems.\n",
    "from surprise import SVD #SVD algorithm\n",
    "from surprise import KNNBasic # Knn algorithm\n",
    "from surprise import Dataset # Utility for loading datasets\n",
    "from surprise import Reader # Allows surprise to interpret the ratings\n",
    "from surprise.model_selection import cross_validate # cross validation utility"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca25a0c2-c4ed-4e45-bc7e-e163ac5b84ee",
   "metadata": {},
   "source": [
    "EDA\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "107d94cd-d905-40b8-b4d5-9b08b39caf36",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "ratings_df = pd.read_csv(\"Ratings.csv\")\n",
    "ratings_df = ratings_df.drop_duplicates() #remove duplicate rows\n",
    "ratings_df.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66d3a657-5ad5-4475-8ca4-939ff5078ff4",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "ratings_df.isnull().sum() #determining null values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fed68e53-8b75-4284-8817-a3a0095cc35f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "ratings_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f595d74b-f7b5-419d-9a34-9cb887f0888f",
   "metadata": {},
   "source": [
    "Ratings does not have a null value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f3744af-90a4-485c-a500-c21e149759d6",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "users_df = pd.read_csv(\"Users.csv\")\n",
    "users_df = users_df.drop_duplicates() #remove duplicate rows\n",
    "users_df.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0bc6a971-fe74-4315-b109-4d83d932f8ea",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "users_df.isnull().sum() #determining null value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48a65aac-0fdc-4964-ac86-bcf466750de8",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "users_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef6421e6-b07f-4187-b81c-4755be34dace",
   "metadata": {},
   "source": [
    "Most of the users does not have Age on the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ed2206e-88ce-4b66-be31-1a7a5ddec9d2",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "books_df = pd.read_csv(\"Books.csv\")\n",
    "books_df = books_df.drop_duplicates() #remove duplicate rows\n",
    "books_df.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "291d1a72-b88a-4a3c-821c-f71c681addc3",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "books_df.isnull().sum() #determining null values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34243999-79cc-4e6b-8c4d-f2bf353c96e1",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "books_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e5f482c9-a7cb-4cb5-b759-5d89f0541568",
   "metadata": {},
   "source": [
    "There are 2 books that has a null value on the Author"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c5f27bb-7e00-4dc8-b375-b462c9b29a3e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#understand unique counts for the dataset\n",
    "\n",
    "num_users = len(ratings_df['User-ID'].unique())\n",
    "num_books = len(ratings_df.ISBN.unique())\n",
    "\n",
    "print('There are {} unique users and {} unique books in this data set'.format(num_users, num_books))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3aca95d-c702-48e8-97d3-1f9931f698da",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#How many ratings per User ID do we have?\n",
    "\n",
    "ratings_df[['User-ID','ISBN']].groupby(['User-ID']).count().hist()\n",
    "plt.title(\"Count of Ratings per User Id\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f75b52d6-62b3-4c3b-84c0-7d91c1df90a0",
   "metadata": {},
   "source": [
    "Most of the books does not have a rating"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1cea357-52a0-4aa1-ab4d-9f87ee5dbd83",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "ratings_df[['User-ID','ISBN']].groupby(['User-ID']).count().describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25675919-adcc-4fa7-8b34-0fb005190a78",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#How many user ratings per movie id do we have\n",
    "\n",
    "ratings_df[['User-ID','ISBN']].groupby(['ISBN']).count().hist()\n",
    "plt.title(\"Count of User Ratings per ISBN\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b2ea1df-0d16-4f56-b1be-8154b0fb548e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "ratings_df[['User-ID','ISBN']].groupby(['ISBN']).count().describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d579efb-0489-4996-97d9-d1598fff871e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#look at ratings distribution\n",
    "\n",
    "ratings_df['Book-Rating'].value_counts().plot.bar(title=\"Count of Rating Score\",)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "87b85fcd-44a2-4cef-8c64-3efb61394516",
   "metadata": {},
   "source": [
    "Preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "94ecd1cf-0e80-4df8-bfaa-27ad38ba7552",
   "metadata": {},
   "source": [
    "Based on the EDA, most of the books does not have a rating and not much users give ratings. That being said, we will have to remove unpopular books and users that rarely rating books for dimension reduction of the data set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4580af70-8462-47b7-ab4a-18c4f321cc22",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "popularity_thres = 10\n",
    "book_rating_cnt_df = ratings_df[['Book-Rating','ISBN']].groupby(['ISBN']).count()\n",
    "popular_book_df = book_rating_cnt_df[book_rating_cnt_df['Book-Rating']>=popularity_thres]\n",
    "\n",
    "\n",
    "filtered_pop_book_df = ratings_df[ratings_df.ISBN.isin(popular_book_df.index.values)]\n",
    "print('shape of original ratings data: ', ratings_df.shape)\n",
    "print('shape of ratings data after dropping unpopular books: ', filtered_pop_books_df.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f1e7cae-afb3-4966-8d50-a7820220c4e0",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#filtering for active users\n",
    "ratings_thres = 10\n",
    "\n",
    "active_users_cnt_df = ratings_df[['User-ID','ISBN']].groupby(['User-ID']).count()\n",
    "active_users_df = active_users_cnt_df[active_users_cnt_df['ISBN']>=ratings_thres]\n",
    "\n",
    "filtered_popular_active_df = filtered_pop_book_df[filtered_pop_book_df.index.isin(active_users_df.index.values)]\n",
    "print('shape of original ratings data: ', filtered_pop_book_df.shape)\n",
    "print('shape of ratings data after dropping both unpopular books and inactive users: ', filtered_popular_active_df.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7111ab6-316e-4b69-bba6-f2be308e1719",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "filtered_popular_active_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f724c374-3236-4ea2-811e-2ce25188dc34",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Let's transform this into a movie-user pivot table\n",
    "# Let's join them up first using a left join operation on movieId\n",
    "\n",
    "filtered_book_ratings_merged_df = pd.merge(filtered_popular_active_df,books_df, how='left', on=['ISBN'])\n",
    "filtered_book_ratings_merged_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "323bd3b9-2e1f-4bf1-82e8-025bd8944f7e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "filtered_book_ratings_merged_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "196c119f-8611-4555-9ba9-287a96f9cf7c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "filtered_book_ratings_merged_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2df047dd-bc5f-4ff4-9098-8f42ca40350c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Now let's pivot the dataframe such that it will have movieId as the index, and userId as columns\n",
    "filtered_book_ratings_df = pd.pivot(filtered_book_ratings_merged_df,index='ISBN', columns='User-ID', values='Book-Rating').fillna(0)\n",
    "filtered_book_ratings_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72d8cee2-73ba-4d5b-8b4e-80f0994464d3",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "book_ratings_mat  = sp.sparse.csr_matrix(filtered_book_ratings_df.values)\n",
    "book_ratings_mat"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa56aa8f-c020-416c-9744-cf8348db43d3",
   "metadata": {},
   "source": [
    "Model Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e1c0a3e-a78c-4851-b0ae-832d2f1d7ff9",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "model_knn = NearestNeighbors(metric='cosine', algorithm='brute', n_neighbors=20, n_jobs=-1)\n",
    "\n",
    "# fit\n",
    "model_knn.fit(book_ratings_mat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79fdea26-65f8-45cc-ba82-c5311449a3a9",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Let's try it out\n",
    "fav_book = \"Myth\"\n",
    "print('You have input book:', fav_book)\n",
    "\n",
    "# find movies that \"match\" title\n",
    "book_matches_df = filtered_book_ratings_merged_df[filtered_book_ratings_merged_df['Book-Title'].str.contains(fav_book, na = False)]\n",
    "book_matches_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf582dd6-efce-49c9-8228-bedc4c062c5a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "print(\"Let's start making recommendations!...\")\n",
    "\n",
    "if(book_matches_df is  None):\n",
    "    print(\"No Matching books :(\")\n",
    "else:\n",
    "    top_recommendations = 10\n",
    "\n",
    "    book_idx= book_matches_df.iloc[0]['ISBN']\n",
    "    \n",
    "    book_idx = filtered_book_ratings_merged_df[filtered_book_ratings_merged_df['ISBN'] == book_idx].index[0]\n",
    "\n",
    "    distances , indices = model_knn.kneighbors(book_ratings_mat[book_idx],n_neighbors=top_recommendations+1)    \n",
    "\n",
    "    rec_book_indices = sorted(list(zip(indices.squeeze().tolist(),distances.squeeze().tolist())),key=lambda x: x[1])[:0:-1]\n",
    "    recommend_frame = []\n",
    " \n",
    "    # we will iterate thru the results and add them to the list\n",
    "    for val in rec_book_indices:\n",
    "        \n",
    "        book_idx = filtered_book_ratings_merged_df.iloc[val[0]]['ISBN']\n",
    "        idx = filtered_book_ratings_merged_df[filtered_book_ratings_merged_df['ISBN'] == book_idx].index\n",
    "        recommend_frame.append({'Book-Title':filtered_book_ratings_merged_df.iloc[idx]['Book-Title'].values[0],'Distance':val[1]})\n",
    "\n",
    "    # place resulting list inside a dataframe\n",
    "    df = pd.DataFrame(recommend_frame,index=range(1,top_recommendations+1))\n",
    "    display(df.sort_values(\"Distance\")) #sort by distance to get the top 10"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f262a792-0fca-4afc-a9f8-83bb48c6742f",
   "metadata": {},
   "source": [
    "Top N Predictors and Hit Rate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1494a96-6eed-44d2-977c-5c9c50bb39fe",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from collections import defaultdict\n",
    "\n",
    "def get_top_n(predictions, n=10):\n",
    "\n",
    "    # First map the predictions to each user.\n",
    "    top_n = defaultdict(list)\n",
    "    for uid, iid, true_r, est, _ in predictions:\n",
    "        # top_n = is a dictionary to map rating to a userid as key\n",
    "        # est = predicted rating\n",
    "        # iid = ISBN\n",
    "        # uid = user id\n",
    "        top_n[uid].append((iid, est))\n",
    "\n",
    "    # Then sort the predictions for each user and retrieve the k highest ones.\n",
    "    for uid, user_ratings in top_n.items():\n",
    "        \n",
    "        # x[1] refers to the est score, which means sort highest to lowest using the rating per user\n",
    "        user_ratings.sort(key=lambda x: x[1], reverse=True)\n",
    "        top_n[uid] = user_ratings[:n]\n",
    "\n",
    "    return top_n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b701e666-5556-421c-9621-717f87aec7a3",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from surprise.model_selection import LeaveOneOut\n",
    "\n",
    "\n",
    "# Let's rebuild our models\n",
    "# A reader is still needed but only the rating_scale param is required.\n",
    "# this indicates our rating is 1 to 10 only\n",
    "\n",
    "reader = Reader(rating_scale=(1, 10))\n",
    "\n",
    "# The columns must correspond to user id, ISBN and ratings (in that order).\n",
    "data = Dataset.load_from_df(filtered_book_ratings_merged_df[['User-ID', 'ISBN', 'Book-Rating']], reader)\n",
    "\n",
    "#Build a \"leave one out\" train/test split for evaluating top-N recommenders\n",
    "LOOCV = LeaveOneOut(n_splits=1, random_state=1)\n",
    "for train, test in LOOCV.split(data):\n",
    "    LOOCVTrain = train\n",
    "    LOOCVTest = test\n",
    "\n",
    "#Save leave one out test predictions\n",
    "leftoutpredictions = LOOCVTest\n",
    "\n",
    "\n",
    "#And build an anti-test-set for building predictions\n",
    "LOOCVAntiTestSet = LOOCVTrain.build_anti_testset()\n",
    "\n",
    "\n",
    "# generate two models\n",
    "knn = KNNBasic()\n",
    "svd = SVD()\n",
    "\n",
    "# fit using generated training set from data\n",
    "knn.fit(LOOCVTrain)\n",
    "svd.fit(LOOCVTrain)\n",
    "\n",
    "# Then predict ratings for all pairs (u, i) that are NOT in the training set (from data)\n",
    "#testset = trainset.build_anti_testset()\n",
    "\n",
    "# generate predictions\n",
    "knn_predictions = knn.test(LOOCVAntiTestSet)\n",
    "svd_predictions = svd.test(LOOCVAntiTestSet)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30c54e61-4a20-4de8-a85a-758a857b0213",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# generate top ten recommendations based on users NOT in the training set\n",
    "knn_top_n = get_top_n(knn_predictions, n=10)\n",
    "svd_top_n = get_top_n(svd_predictions, n=10)\n",
    "\n",
    "# Print the recommended items for each user\n",
    "print(\"\")\n",
    "print(\"top n recommendations for knn\")\n",
    "for uid, user_ratings in knn_top_n.items():\n",
    "    print(uid, [iid for (iid, _) in user_ratings])\n",
    "\n",
    "print(\"\")\n",
    "print(\"top n recommendations for svd\")   \n",
    "for uid, user_ratings in svd_top_n.items():\n",
    "    print(uid, [iid for (iid, _) in user_ratings])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b0c9023-4361-47c7-8703-6b6a22cbc3ef",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# utility function to get the book title based on the ISBN\n",
    "def get_title_from_id(idx):\n",
    "    return filtered_book_ratings_merged_df[filtered_book_ratings_merged_df['ISBN']==idx]['Book-Title'].values[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2b1d2ec-0184-4651-99a9-1371a13a526f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Print the recommended items for each user\n",
    "print(\"\")\n",
    "print(\"top n recommendations for knn\")\n",
    "for uid, user_ratings in knn_top_n.items():\n",
    "    print(uid, [get_title_from_id(iid) for (iid, _) in user_ratings])\n",
    "\n",
    "print(\"\")\n",
    "print(\"top n recommendations for svd\")   \n",
    "for uid, user_ratings in svd_top_n.items():\n",
    "    print(uid, [get_title_from_id(iid) for (iid, _) in user_ratings])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae20e4ed-0648-46e8-bb71-f440e1660e50",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# HIT RATE - This is usually used for top n recomendation systems, since we're not really predicting against anything\n",
    "# Tries to measure how many books did we predict are in the top movies of a user we left out,\n",
    "# are also in the top n movies we predicted\n",
    "\n",
    "# Generate the top n recommendation for a user and compare them to those the user has rated, liked or read.\n",
    "# If they match then increase the hit rate by 1, do this for the complete training set to get the hit rate.\n",
    "# The higher the better, but if its very low or zero, it means we need to use more data \n",
    "\n",
    "def hitrate(topNpredictions, leftoutpredictions):\n",
    "    userHitRates = []  # create list of user hit rates\n",
    "\n",
    "    # iterate per user per book ISBN\n",
    "    for leftout in leftoutpredictions:\n",
    "        uid = leftout[0]\n",
    "        leftout_isbn = leftout[1]\n",
    "\n",
    "        print(\"uid: \", uid)\n",
    "        print(\"left out ISBN: \", leftout_isbn)\n",
    "\n",
    "        predicted_isbns = [predISBN for predISBN, predRating in topNpredictions[uid]]\n",
    "\n",
    "        print(predicted_isbns)\n",
    "\n",
    "        hits = 1 if leftout_isbn in predicted_isbns else 0\n",
    "        total = len(predicted_isbns)\n",
    "        userHitRate = hits / total if total != 0 else 0  # handle division by zero\n",
    "\n",
    "        userhitRate_dict = {\"uid\": uid, \"userhitrate\": userHitRate}\n",
    "        userHitRates.append(userhitRate_dict)\n",
    "\n",
    "    return pd.DataFrame(userHitRates)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78f59461-72cb-4512-b816-b4f34bc684c6",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "knn_top_n[3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "222be16c-7d8a-401d-9ac6-2c61d44cf06c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "knn_top_n.items()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b442d92e-62e2-4028-b9e2-0c84554f5979",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Hit rate for our models\n",
    "hitrate_df = pd.DataFrame()\n",
    "hitrate_df['knn'] = [hitrate(knn_top_n, leftoutpredictions)]\n",
    "hitrate_df['svd'] = [hitrate(svd_top_n, leftoutpredictions)]\n",
    "hitrate_df.index = ['hitrate'] \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8472b6f9-be46-4a2c-a8a1-654d7fbddbb4",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Let's append this to our metric dataframe\n",
    "final_metric_df = metric_df\n",
    "final_metric_df.index = ['Fold 1','Fold 2','Fold 3', 'Mean','Std']\n",
    "print(\"Metric Comparison (RSME)\")\n",
    "display(final_metric_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56b78c87-27bf-402c-8499-9dc511f447fa",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "print(\"SVD hitrate metrics\")\n",
    "hitrate(svd_top_n, leftoutpredictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2c74998-1b79-4e02-b362-2264b14c5fa2",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "print(\"KNN hitrate metrics\")\n",
    "hitrate(knn_top_n, leftoutpredictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44ceacb6-fc37-42aa-8733-1d12f8fa50fc",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
